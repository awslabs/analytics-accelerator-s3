name: Build and upload s3 seekable stream jars to s3a treatment bucket

# Controls when the action will run. Invokes the workflow on push events but only for the main branch
on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

env:
  AWS_REGION : "us-east-1" #Change to reflect your Region
  S3_BUCKET : "seekable-stream-jars"
  STATE_MACHINE_ARN : "arn:aws:states:us-east-1:696132882038:stateMachine:BenchmarkOrchestratorStateMachine-prod-us-east-1-696132882038"

# Permission can be added at job level or workflow level    
permissions:
      id-token: write   # This is required for requesting the JWT
      contents: read    # This is required for actions/checkout

jobs:
  BuildAndUploadJarToS3:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-java@v4
        with:
          java-version: '11'
          distribution: 'temurin'

      - name: Setup Gradle
        uses: gradle/actions/setup-gradle@417ae3ccd767c252f5661f1ace9f835f9654f2b5 # v3.1.0

      - name: Build with Gradle
        run: ./gradlew uberJar
      
      - name: Configure aws credentials
        uses: aws-actions/configure-aws-credentials@v1.7.0
        with:
          role-to-assume: arn:aws:iam::696132882038:role/S3SkylineGithubRole #change to reflect your IAM roleâ€™s ARN
          role-session-name: GitHub_to_AWS_via_FederatedOIDC
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Upload input-stream jar to s3a treatment bucket
        run: aws s3 cp --recursive input-stream/build/libs/input-stream-uber.jar s3://${{ env.S3_BUCKET }}/s3a/input-stream-1.0.0.jar
      
      - name: Upload object-client uber jar to s3a treatment bucket
        run: aws s3 cp --recursive object-client/build/libs/object-client-uber.jar s3://${{ env.S3_BUCKET }}/s3a/object-client-1.0.0.jar

      - name: Trigger S3A Benchmarks
        run:  aws stepfunctions start-execution --state-machine-arn ${{ env.STATE_MACHINE_ARN}} --input "{\"InputConfigurations\":[{\"AzId\":\"use1-az1\",\"Runner\":{\"JavaClassPath\":\"datalake.connectors.benchmark.tools.experiments.RunOpenSourceSparkAQBE\",\"JavaExecArgs\":\"--numIterations 11 --datasetObjectSize 100mb --conf spark.hadoop.fs.s3a.experimental.input.fadvise=random\",\"JobIdPrefix\":\"Baseline\",\"S3UriPrefix\":\"s3-skyline-us-east-1\",\"AthenaAndCwRegion\":\"us-east-1\",\"Namespace\":\"shared\",\"AccountId\":\"696132882038\",\"Connector\":\"s3a\"}},{\"AzId\":\"use1-az1\",\"Runner\":{\"JavaClassPath\":\"datalake.connectors.benchmark.tools.experiments.RunOpenSourceSparkAQBE\",\"JavaExecArgs\":\"--numIterations 11 --datasetObjectSize 100mb --jars s3://seekable-stream-jars/hadoop-aws-3.5.0-SNAPSHOT.jar s3://seekable-stream-jars/input-stream-1.0.0.jar s3://seekable-stream-jars/object-client-1.0.0.jar --conf spark.hadoop.fs.s3a.seekable.stream.enabled=true spark.hadoop.fs.s3a.experimental.input.fadvise=random\",\"JobIdPrefix\":\"Treatment\",\"S3UriPrefix\":\"s3-skyline-us-east-1\",\"AthenaAndCwRegion\":\"us-east-1\",\"Namespace\":\"shared\",\"AccountId\":\"696132882038\",\"Connector\":\"s3a\"}}]}"

