name: Build and upload Hadoop jar to benchmarking bucket

# Controls when the action will run. Invokes the workflow on push events but only for the main branch
on:
  push:
    branches:
      - main
      - cicd-builds

env:
  AWS_REGION :  ${{ vars.AWS_REGION }} # Change to reflect your region
  S3_BUCKET : ${{ vars.S3_BUCKET }}
  ROLE_TO_ASSUME: ${{ secrets.ASSUME_ROLE_ARN }}

# Permission can be added at job level or workflow level
permissions:
  id-token: write   # This is required for requesting the JWT
  contents: read    # This is required for actions/checkout

jobs:
  BuildHadoopAndUploadJarToS3:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-java@v4
        with:
          java-version: '11'
          distribution: 'corretto'

      - name: Set up Maven
        uses: stCarolas/setup-maven@v4.2
        with:
          maven-version: 3.9.4

      - name: Setup Gradle
        uses: gradle/actions/setup-gradle@417ae3ccd767c252f5661f1ace9f835f9654f2b5 # v3.1.0

      - name: Build and publish to local Maven with Gradle
        run: |
          ./gradlew publishToMavenLocal

      - name: Publish uber jar to local Maven
        run: mvn install:install-file -Dfile=input-stream/build/libs/input-stream-all.jar -DgroupId=com.amazon.connector.s3 -DartifactId=input-stream -Dversion=1.0.0 -Dpackaging=jar -DgeneratePom=true

      - name: Setup Hadoop SSH deploy key
        uses: webfactory/ssh-agent@v0.7.0
        with:
          ssh-private-key: ${{ secrets.HADOOP_STAGING_SSH_KEY }}

      - name: Checkout Hadoop
        uses: actions/checkout@v4
        with:
          repository: amazon-contributing/private-hadoop-staging
          ref: s3-connector-framework
          path: hadoop
          ssh-key: ${{ secrets.HADOOP_STAGING_SSH_KEY }}

      - name: Build Hadoop jar
        run: mvn clean install -DskipTests
        working-directory: hadoop

      - name: Configure aws credentials
        uses: aws-actions/configure-aws-credentials@v1.7.0
        with:
          role-to-assume: ${{ env.ROLE_TO_ASSUME }}
          role-session-name: GitHub_to_AWS_via_FederatedOIDC
          aws-region: ${{ env.AWS_REGION }}

      - name: Upload hadoop-aws JAR to S3a treatment bucket
        run: aws s3 cp /home/runner/.m2/repository/org/apache/hadoop/hadoop-aws/3.5.0-SNAPSHOT/hadoop-aws-3.5.0-SNAPSHOT.jar s3://${{ env.S3_BUCKET }}/s3a/hadoop-aws-3.5.0-SNAPSHOT.jar
